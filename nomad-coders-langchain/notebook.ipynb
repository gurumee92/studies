{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\") \n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요, 제 이름은 구르미입니다. 한국과 일본 사이의 거리는 직선거리로 약 900km 정도입니다. 그러나 실제로 이동하는 경우에는 해상이나 공기로 이동하므로 더 길어질 수 있습니다.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 predict message\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "\n",
    "example_prompt = [\n",
    "    SystemMessage(content=\"너는 지리학 전문가야, 오로지 한국어로만 대답할 수 있어\"),\n",
    "    AIMessage(content=\"안녕 나는 구르미야\"),\n",
    "    HumanMessage(content=\"한국과 일본 사이의 거리는 얼마인가요? 그리고 너의 이름은 뭔가요?\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages=example_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='미국과 중국 사이의 거리는 직선거리로 약 11,000km 정도입니다. 내 이름은 륜륜이야.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 prompt template\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "# template = PromptTemplate.from_template(\"{country_a}과 {country_b} 사이의 거리는 얼마인가요? 그리고 너의 이름은 뭔가요?\")\n",
    "# prompt = template.format(country_a=\"멕시코\", country_b=\"태국\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너는 지리학 전문가야, 오로지 {language}로만 대답할 수 있어\"),\n",
    "        (\"ai\", \"안녕 나는 {name}야\"),\n",
    "        (\"human\", \"{country_a}과 {country_b} 사이의 거리는 얼마인가요? 그리고 너의 이름은 뭔가요?\"),\n",
    "    ]\n",
    ")\n",
    "example_prompt = template.format_messages(\n",
    "    language=\"한국어\",\n",
    "    name=\"륜륜이\",\n",
    "    country_a=\"중국\",\n",
    "    country_b=\"미국\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(example_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, output: str):\n",
    "        items = output.split(\",\")    \n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello,how,are,you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mercury',\n",
       " 'Venus',\n",
       " 'Earth',\n",
       " 'Mars',\n",
       " 'Jupiter',\n",
       " 'Saturn',\n",
       " 'Uranus',\n",
       " 'Neptune',\n",
       " 'Pluto']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma serperated in a list of max {max_items}. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "]\n",
    ")\n",
    "\n",
    "example_prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the planets?\"\n",
    ")\n",
    "result = chat.predict_messages(example_prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pikachu',\n",
       " 'Charmander',\n",
       " 'Bulbasaur',\n",
       " 'Squirtle',\n",
       " 'Jigglypuff',\n",
       " 'Eevee',\n",
       " 'Snorlax',\n",
       " 'Mewtwo',\n",
       " 'Gengar']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma serperated in a list of max {max_items}. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# |로 묶을 수 있는 컴포넌트 prompt, chat, parser, retriever, tool \n",
    "chain = template | chat | CommaOutputParser()\n",
    "# 1. dict -> prompt -> chat message -> parser\n",
    "chain.invoke({\"max_items\": 10, \"question\": \"What are the poketmons?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! How about making some delicious Bibimbap? It's a popular Korean dish that consists of mixed rice with vegetables, meat, and a spicy sauce. Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 2 cups cooked white rice\n",
      "- 1 carrot, julienned\n",
      "- 1 zucchini, julienned\n",
      "- 1 cup bean sprouts\n",
      "- 1 cup spinach\n",
      "- 200g beef (you can also use chicken or tofu as a substitute)\n",
      "- 2 cloves garlic, minced\n",
      "- 2 tbsp soy sauce\n",
      "- 1 tbsp sesame oil\n",
      "- 1 tbsp sugar\n",
      "- 2 tbsp vegetable oil\n",
      "- 4 eggs\n",
      "- Kimchi (optional, for serving)\n",
      "- Gochujang (Korean red chili paste, for serving)\n",
      "\n",
      "Instructions:\n",
      "1. Marinate the beef: In a bowl, mix the beef with minced garlic, soy sauce, sesame oil, and sugar. Let it marinate for at least 30 minutes.\n",
      "2. Cook the rice according to package instructions and set aside.\n",
      "3. In a pan, heat 1 tbsp of vegetable oil over medium heat. Stir-fry the marinated beef until cooked through. Remove from the pan and set aside.\n",
      "4. In the same pan, add another tbsp of vegetable oil. Stir-fry the carrot and zucchini until slightly softened. Remove from the pan and set aside.\n",
      "5. Blanch the bean sprouts and spinach in boiling water for a few minutes. Drain and squeeze out excess water.\n",
      "6. In the pan, fry the eggs sunny side up or to your liking.\n",
      "7. To assemble the Bibimbap, divide the rice into bowls. Arrange the cooked beef, vegetables, and fried egg on top of the rice.\n",
      "8. Serve with kimchi and a dollop of Gochujang on the side.\n",
      "9. Mix everything together before eating to enjoy the flavors of Bibimbap.\n",
      "\n",
      "Enjoy your homemade Korean Bibimbap! Feel free to customize the ingredients to your liking and make it your own.For a vegetarian version of Bibimbap, you can easily substitute the beef with tofu or tempeh. Here's how you can prepare the tofu as a substitute:\n",
      "\n",
      "Ingredients:\n",
      "- 200g firm tofu, pressed and cubed\n",
      "- 2 cloves garlic, minced\n",
      "- 2 tbsp soy sauce\n",
      "- 1 tbsp sesame oil\n",
      "- 1 tbsp sugar\n",
      "\n",
      "Instructions:\n",
      "1. Press the tofu to remove excess water. You can do this by wrapping the tofu block in a clean kitchen towel and placing a heavy object on top for about 15-20 minutes.\n",
      "2. In a bowl, mix the cubed tofu with minced garlic, soy sauce, sesame oil, and sugar. Let it marinate for at least 30 minutes.\n",
      "3. In a pan, heat 1 tbsp of vegetable oil over medium heat. Stir-fry the marinated tofu until golden brown and slightly crispy. Remove from the pan and set aside.\n",
      "\n",
      "Follow the rest of the recipe as it is, using the tofu instead of beef. This vegetarian Bibimbap will still be flavorful and satisfying. Enjoy your meat-free Korean dish!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"For a vegetarian version of Bibimbap, you can easily substitute the beef with tofu or tempeh. Here's how you can prepare the tofu as a substitute:\\n\\nIngredients:\\n- 200g firm tofu, pressed and cubed\\n- 2 cloves garlic, minced\\n- 2 tbsp soy sauce\\n- 1 tbsp sesame oil\\n- 1 tbsp sugar\\n\\nInstructions:\\n1. Press the tofu to remove excess water. You can do this by wrapping the tofu block in a clean kitchen towel and placing a heavy object on top for about 15-20 minutes.\\n2. In a bowl, mix the cubed tofu with minced garlic, soy sauce, sesame oil, and sugar. Let it marinate for at least 30 minutes.\\n3. In a pan, heat 1 tbsp of vegetable oil over medium heat. Stir-fry the marinated tofu until golden brown and slightly crispy. Remove from the pan and set aside.\\n\\nFollow the rest of the recipe as it is, using the tofu instead of beef. This vegetarian Bibimbap will still be flavorful and satisfying. Enjoy your meat-free Korean dish!\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\"), \n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "final_chain = { \"recipe\": chef_chain } | veg_chain    \n",
    "final_chain.invoke({\"cuisine\": \"korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        There are two Koreas - North Korea and South Korea.\n",
      "        Capital of South Korea: Seoul\n",
      "        Capital of North Korea: Pyongyang\n",
      "        Language: Korean\n",
      "        Food: Kimchi and Bibimbap\n",
      "        Currency: South Korea - South Korean Won, North Korea - North Korean Won\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        There are two Koreas - North Korea and South Korea.\\n        Capital of South Korea: Seoul\\n        Capital of North Korea: Pyongyang\\n        Language: Korean\\n        Food: Kimchi and Bibimbap\\n        Currency: South Korea - South Korean Won, North Korea - North Korean Won\\n        ')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 Few-shot learning, 예시를 줘서 학습시키기\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, \n",
    "                  streaming=True,\n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "]) \n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are geography expert.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "    \n",
    "chain = final_prompt | chat\n",
    "chain.invoke({\"country\": \"China\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
